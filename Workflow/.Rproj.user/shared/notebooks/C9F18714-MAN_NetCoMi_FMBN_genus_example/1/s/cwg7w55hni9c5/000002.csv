"0",""
"0","if(keep_time) tic(""calculate diversity post-filter"")"
"0",""
"0","# estimate diversity for each object of the physeq_list_5, returns a list with the results"
"0","# extract and put together with metadata"
"0","# will generate warnings"
"0",""
"0","div_est_postfilter <- map_dfr(physeq_list_5, estimate_richness, split = F, "
"0","                              measures = c(""Observed"",""Chao1"",""Shannon""), .id = ""label"")"
"2","The data you have provided does not have
any singletons. This is highly suspicious. Results of richness
estimates (for example) are probably unreliable, or wrong, if you have already
trimmed low-abundance taxa from the data.

We recommended that you find the un-trimmed data and retry."
"2","The data you have provided does not have
any singletons. This is highly suspicious. Results of richness
estimates (for example) are probably unreliable, or wrong, if you have already
trimmed low-abundance taxa from the data.

We recommended that you find the un-trimmed data and retry."
"2","The data you have provided does not have
any singletons. This is highly suspicious. Results of richness
estimates (for example) are probably unreliable, or wrong, if you have already
trimmed low-abundance taxa from the data.

We recommended that you find the un-trimmed data and retry."
"0","div_est_postfilter <- mutate(div_est_postfilter, Pielou_J = Shannon/log(Observed))"
"0",""
"0","# calculate and add average Bray-Curtis dissimilarity"
"0","meanbcdist <- map(physeq_list_5, phyloseq::distance, method=""bray"")"
"0","div_est_postfilter$ave_BC <- unlist(map(meanbcdist, mean))"
"0",""
"0","row.names(div_est_postfilter) <- names(physeq_list_5)"
"0","# save for further use"
"0","save(div_est_postfilter, "
"0","     file = paste(file.path(output_folder,out_filename_pref), ""_divpostfilter.Rdata"",sep=""""))"
"0",""
"0","# an alternative could be to use it on div_est_prefilter"
"0","study_metadata <- left_join(study_metadata, div_est_postfilter)"
"2","Joining, by = ""label""
"
"0","if(keep_time) toc()"
"1","calculate diversity post-filter: 0.233 sec elapsed
"
"0","# calculate network statistics with netAnalyze"
"0","if(keep_time) tic(""Calculate network statistics"")"
"0",""
"0","# the list for the methods within the dataset"
"0","net_stats <- vector(""list"", length = length(MAN_inf_results))"
"0","# net_stat_results is a list, do the calculation for each of the datasets, all inference methods"
"0","for(i in seq_along(MAN_inf_results)){"
"0","  name <- names(MAN_inf_results)[i]"
"0","  if(verbose_output) cat(""Calculating network stats for"",name,""\n"")"
"0","  net_stat_results <- vector(""list"", length = length(MAN_inf_results[[i]]))"
"0","  for(j in seq_along(MAN_inf_results[[i]])){"
"0","    mthd <- names(MAN_inf_results[[i]])[j]"
"0","    if(verbose_output) cat(""method"",mthd,""\n"")"
"0","    # consider reducing argument hubQuant to 0.75-0.90 default is 0.95),"
"0","    net_stat_results[[j]] <- calculate_net_stats(MAN_inf_results[[i]][[j]])"
"0","  }"
"0","  names(net_stat_results)<-names(MAN_inf_results[[i]])"
"0","  net_stats[[i]] <- net_stat_results"
"0","  names(net_stats)[i]<-names(MAN_inf_results)[i]"
"0","}"
"1","Calculating network stats for"
"1"," "
"1","ST106_FMBN_ps"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spieceasi"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spring"
"1"," "
"1","
"
"2","Error in netAnalyze(microNet_obj, centrLCC = TRUE, avDissIgnoreInf = FALSE,  : 
  Network is empty.
"
"1","method"
"1"," "
"1","sparcc"
"1"," "
"1","
"
"1","method"
"1"," "
"1","ccrepe"
"1"," "
"1","
"
"1","Calculating network stats for"
"1"," "
"1","ST110_FMBN_ps"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spieceasi"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spring"
"1"," "
"1","
"
"1","method"
"1"," "
"1","sparcc"
"1"," "
"1","
"
"1","method"
"1"," "
"1","ccrepe"
"1"," "
"1","
"
"1","Calculating network stats for"
"1"," "
"1","ST115_FMBN_ps"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spieceasi"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spring"
"1"," "
"1","
"
"2","Error in netAnalyze(microNet_obj, centrLCC = TRUE, avDissIgnoreInf = FALSE,  : 
  Network is empty.
"
"1","method"
"1"," "
"1","sparcc"
"1"," "
"1","
"
"1","method"
"1"," "
"1","ccrepe"
"1"," "
"1","
"
"1","Calculating network stats for"
"1"," "
"1","ST131_FMBN_ps"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spieceasi"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spring"
"1"," "
"1","
"
"2","Error in netAnalyze(microNet_obj, centrLCC = TRUE, avDissIgnoreInf = FALSE,  : 
  Network is empty.
"
"1","method"
"1"," "
"1","sparcc"
"1"," "
"1","
"
"1","method"
"1"," "
"1","ccrepe"
"1"," "
"1","
"
"2","Weighted degree used (unweighted degree not meaningful for a fully connected network).
"
"2","Argument 'normDeg' set to FALSE
"
"2","(no normalization implemented for weighted degree).
"
"1","Calculating network stats for"
"1"," "
"1","ST136_FMBN_ps"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spieceasi"
"1"," "
"1","
"
"1","method"
"1"," "
"1","spring"
"1"," "
"1","
"
"1","method"
"1"," "
"1","sparcc"
"1"," "
"1","
"
"1","method"
"1"," "
"1","ccrepe"
"1"," "
"1","
"
"0","rm(net_stat_results, meanbcdist, mthd)"
"0","if(keep_time) toc()"
"1","Calculate network statistics: 0.478 sec elapsed
"
"0","# extracting global network properties"
"0",""
"0","if(keep_time) tic(""Extraction global network properties"")"
"0","# extracting the global network stats "
"0","global_props_list_a <-vector(""list"",length(net_stats))"
"0","global_props_list_l <-vector(""list"",length(net_stats)) "
"0","global_props_list_all <-vector(""list"",length(inf_methods))"
"0","global_props_list_lcc <-vector(""list"",length(inf_methods))"
"0","for (i in seq_along(net_stats)){"
"0","  dataset <- names(net_stats)[i]"
"0","  for (j in seq_along(net_stats[[i]])){"
"0","    if(class(net_stats[[i]][[j]])!= ""microNetProps""){"
"0","      next"
"0","    } else{"
"0","      nnodes <- sum(net_stats[[i]][[j]]$centralities$degree1>0)"
"0","      ntaxa <- nrow(net_stats[[i]][[j]]$input$assoMat1)"
"0","      nposedge <- sum(net_stats[[i]][[j]]$input$assoMat1[lower.tri(net_stats[[i]][[j]]$input$assoMat1)]>0)"
"0","      nnegedge <- sum(net_stats[[i]][[j]]$input$assoMat1[lower.tri(net_stats[[i]][[j]]$input$assoMat1)]<0)"
"0","      extra_prop_vector <- c(nnodes, ntaxa, nposedge, nnegedge)"
"0","      names(extra_prop_vector) <- c(""nnodes"", ""ntaxa"", ""nposedge"", ""nnegedge"")"
"0","      global_props_list_all[[j]] <- c(unlist(net_stats[[i]][[j]]$globalProps),extra_prop_vector)"
"0","      global_props_list_lcc[[j]] <- c(unlist(net_stats[[i]][[j]]$globalPropsLCC),extra_prop_vector)"
"0","      names(global_props_list_all)[j] <- names(global_props_list_lcc)[j]<- names(net_stats[[i]][j])"
"0","    }"
"0","    # create data frame with results"
"0","    all_df <- bind_rows(global_props_list_all, .id = ""method"")"
"0","    lcc_df <- bind_rows(global_props_list_lcc, .id = ""method"") "
"0","  }"
"0","  global_props_list_a[[i]] <- all_df"
"0","  global_props_list_l[[i]] <- lcc_df"
"0","  names(global_props_list_a)[i] <- names(global_props_list_l)[i] <- names(net_stats)[i]"
"0","}"
"0","# note that str_sub only works if you have <=9 inference methods in inf_methods"
"0","global_all_df <- bind_rows(global_props_list_a, .id = ""dataset"") "
"0","global_lcc_df <- bind_rows(global_props_list_l, .id = ""dataset"") "
"0",""
"0",""
"0","global_all_df <- left_join(global_all_df, "
"0","                           select(study_metadata,label, obj_type, target, "
"0","                                  region, platform, samples, type, Observed, "
"0","                                  Chao1, Shannon, Pielou_J, ave_BC), "
"0","                           by = c(""dataset"" = ""label"")) %>%"
"0","  mutate(across(where(is.numeric), ~na_if(.,Inf)))"
"0","global_lcc_df <- left_join(global_lcc_df, "
"0","                           select(study_metadata,label, obj_type, target, "
"0","                                  region, platform, samples, type, Observed, "
"0","                                  Chao1, Shannon, Pielou_J, ave_BC), "
"0","                           by = c(""dataset"" = ""label"")) %>%"
"0","  mutate(across(where(is.numeric), ~na_if(.,Inf)))"
"0",""
"0","# both might contain Inf which are replaced by NA (using dplyr::na_if()) to be handled"
"0","# correctly if doing PCA by pairwise deletion."
"0","# the problem only occurs in avPath1 and clustCoef1, but I am handling it with a scoped mutate"
"0","# a better solution might be the use of hablar::rationalize()"
"0",""
"0",""
"0","# save the data frames for further use"
"0","write_tsv(global_all_df, file = paste(file.path(output_folder,out_filename_pref), ""_netpropall.txt"",sep=""""))"
"0","write_tsv(global_lcc_df, file = paste(file.path(output_folder,out_filename_pref), ""_netproplcc.txt"",sep=""""))"
"0",""
"0","# print a summary table"
"0","global_all_df"
