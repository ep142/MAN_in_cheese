dataset <- names(net_stats)[i]
for (j in seq_along(net_stats[[i]])){
if(class(net_stats[[i]][[j]])!= "microNetProps"){
next
} else{
nnodes <- sum(net_stats[[i]][[j]]$centralities$degree1>0)
ntaxa <- nrow(net_stats[[i]][[j]]$input$assoMat1)
nposedge <- sum(net_stats[[i]][[j]]$input$assoMat1[lower.tri(net_stats[[i]][[j]]$input$assoMat1)]>0)
nnegedge <- sum(net_stats[[i]][[j]]$input$assoMat1[lower.tri(net_stats[[i]][[j]]$input$assoMat1)]<0)
extra_prop_vector <- c(nnodes, ntaxa, nposedge, nnegedge)
names(extra_prop_vector) <- c("nnodes", "ntaxa", "nposedge", "nnegedge")
global_props_list_all[[j]] <- c(unlist(net_stats[[i]][[j]]$globalProps),extra_prop_vector)
global_props_list_lcc[[j]] <- c(unlist(net_stats[[i]][[j]]$globalPropsLCC),extra_prop_vector)
names(global_props_list_all)[j] <- names(global_props_list_lcc)[j]<- names(net_stats[[i]][j])
}
# create data frame with results
all_df <- bind_rows(global_props_list_all, .id = "method")
lcc_df <- bind_rows(global_props_list_lcc, .id = "method")
}
global_props_list_a[[i]] <- all_df
global_props_list_l[[i]] <- lcc_df
names(global_props_list_a)[i] <- names(global_props_list_l)[i] <- names(net_stats)[i]
}
# note that str_sub only works if you have <=9 inference methods in inf_methods
global_all_df <- bind_rows(global_props_list_a, .id = "dataset")
global_lcc_df <- bind_rows(global_props_list_l, .id = "dataset")
global_all_df <- left_join(global_all_df,
select(study_metadata,label, obj_type, target,
region, platform, samples, type, Observed,
Chao1, Shannon, Pielou_J, ave_BC),
by = c("dataset" = "label")) %>%
mutate(across(where(is.numeric), ~na_if(.,Inf)))
global_lcc_df <- left_join(global_lcc_df,
select(study_metadata,label, obj_type, target,
region, platform, samples, type, Observed,
Chao1, Shannon, Pielou_J, ave_BC),
by = c("dataset" = "label")) %>%
mutate(across(where(is.numeric), ~na_if(.,Inf)))
# both might contain Inf which are replaced by NA (using dplyr::na_if()) to be handled
# correctly if doing PCA by pairwise deletion.
# the problem only occurs in avPath1 and clustCoef1, but I am handling it with a scoped mutate
# a better solution might be the use of hablar::rationalize()
# save the data frames for further use
write_tsv(global_all_df, file = paste(file.path(output_folder,out_filename_pref), "_netpropall.txt",sep=""))
write_tsv(global_lcc_df, file = paste(file.path(output_folder,out_filename_pref), "_netproplcc.txt",sep=""))
# print a summary table
global_all_df
rm(global_props_list_a, global_props_list_l, global_props_list_all,
global_props_list_lcc, all_df, lcc_df, nnodes, ntaxa, nposedge, nnegedge, extra_prop_vector)
if(play_audio) beep(sound = 6)
if(keep_time) toc()
# extract node properties
# using a loop takes slightly longer that using functionals but handles names better
# note that when using ASVs comparing nodes between datasets does not make much sense
if(keep_time) tic("Extracting node properties")
node_stats <- vector("list", length = length(net_stats))
for (i in seq_along(net_stats)) {
node_properties <- node_stat_list[[i]]
if(verbose_output) cat("extracting node stats for", names(net_stats)[i],"\n")
for (j in seq_along(net_stats[[i]])) {
if (class(net_stats[[i]][[j]]) == "microNetProps") {
node_stats[[i]][[j]] <- extract_node_stats(net_stat_list = net_stats[[i]][[j]],
nodestat = node_properties)
method <- names(net_stats[[i]])[j]
dataset <- names(net_stats)[i]
nrows <- nrow(node_stats[[i]][[j]])
node_stats[[i]][[j]] <- bind_cols(
dataset = rep(dataset,nrows),
method = rep(method,nrows),
node_stats[[i]][[j]]
)
} else {
cat("no node stats to return for",
names(net_stats)[i],
names(node_stats[[i]])[j],
"\n")
next
}
}
node_stats[[i]]<-bind_rows(node_stats[[i]])
}
node_stats_df <- bind_rows(node_stats)
# perform some tidying
node_stats_df <- node_stats_df %>%
tidyr::separate(dataset, into = c("Study", "Accn_n", "suf"), sep = "_", remove = F) %>%
dplyr::select(-Accn_n, -suf) %>%
mutate(label2 = if_else(!str_detect(dataset, "FMBN"),str_c(label, Study, sep = "_"), label))
# label2 is only necessary when using ASVs or OTUs, not if there has been taxonomic agglomeration
# consider removing the mutate instruction
write_tsv(node_stats_df, file = paste(file.path(output_folder,out_filename_pref), "_nodestats_df.txt",sep=""))
rm(node_stats)
if(play_audio) beep(sound = 6)
if(keep_time) toc()
if(keep_time) tic("List with tidygraph objects created")
# creating a tidygraph object for each net
tidygraph_list <- vector("list", length = length(MAN_inf_results))
for(i in seq_along(MAN_inf_results)){
if(verbose_output) cat("Converting in tidygraphs for", names(MAN_inf_results)[i],"\n")
# the warning, if any, is not very informative, should consider passing names of datasets and methods
tidygraph_list[[i]] <- MAN_inf_results[[i]] %>% map(microNet_to_tidygraph, fail_w_err = F, use_asso_matrix = T)
}
names(tidygraph_list)<-names(MAN_inf_results)
if(keep_time) toc()
# optionally merge further node stats (depends on merge_n_stats)
# and calculate edge betweenness (depends on calc_e_betw)
# I am using a loop
if(keep_time) tic("Stats added to tidygraphs, edge dataframe created")
tidygraph_list_wstats <- vector("list", length = length(tidygraph_list))
# the list with the edge data frames
edge_list <- vector("list", length = length(tidygraph_list))
for(i in seq_along(tidygraph_list_wstats)){
# need to be reset
inner_tgl <- vector("list", length = length(tidygraph_list[[i]]))
inner_el <- vector("list", length = length(tidygraph_list[[i]]))
dtst <- names(tidygraph_list)[i]
for(j in seq_along(inner_tgl)){
if(is.tbl_graph(tidygraph_list[[i]][[j]])){
mthd = names(tidygraph_list[[i]])[j]
nstats <- node_stats_df %>% dplyr::filter(dataset == dtst & method == mthd)
inner_tgl[[j]] <- merge_stats(tg = tidygraph_list[[i]][[j]],
node_stats = nstats,
ebetw = calc_e_betw)
# extract edge tibble
inner_el[[j]] <- inner_tgl[[j]] %>%
activate(edges) %>%
as_tibble() %>%
mutate(method = mthd)
# do naming
names(inner_tgl)[j] <- names(inner_el)[j] <- names(tidygraph_list[[i]])[j]
} else {
next
}
}
tidygraph_list_wstats[[i]] <- inner_tgl
edge_list[[i]] <- bind_rows(inner_el)
edge_list[[i]] <- edge_list[[i]] %>%
mutate(dataset = dtst) %>% dplyr::select(dataset, method, !(dataset:method))
names(tidygraph_list_wstats)[i] <- names(edge_list)[i] <- names(tidygraph_list)[i]
}
rm(nstats)
# build and fix the edge df
edge_list_df <- bind_rows(edge_list)
edge_list_df <- edge_list_df %>%
mutate(name_from_sorted = if_else(from_name < to_name, from_name, to_name),
name_to_sorted = if_else(from_name < to_name, to_name, from_name)) %>%
mutate(edge_name = str_c(name_from_sorted, name_to_sorted, sep = "--"))
write_tsv(edge_list_df, file = paste(file.path(output_folder,out_filename_pref), "_edgelist_df.txt",sep=""))
if(keep_time) toc()
# make Venn plots
# I am using a loop
if(do_Venn){
if(keep_time) tic("Venn plots created and saved")
Venn_list <- vector("list", length(tidygraph_list))
for(i in seq_along(tidygraph_list)){
# need to select only elements of class tbl_graph
tblgrphs <- map_lgl(tidygraph_list[[i]], is.tbl_graph)
names(Venn_list) <- names(tidygraph_list)
if(length(tidygraph_list[[i]][tblgrphs])>1){
inner_list <- map(tidygraph_list[[i]][tblgrphs], function(x) as_ids(E(x)))
Venn_title <- names(tidygraph_list)[i]
Venn_file <- paste(file.path(output_folder,out_filename_pref),"_",Venn_title, "_venns.tiff",sep="")
my_fill <- (2:5)[1:length(tidygraph_list[[i]][tblgrphs])]
Venn_list[[i]] <- venn.diagram(inner_list,
fill = my_fill,
alpha = 0.3,
filename = Venn_file,
margin = 0.05,
main = Venn_title,
main.cex = 1.5,
main.fontface = "bold",
main.fontfamily = "sans",
main.pos = c(0.5, 1.05)
)
}
}
rm(inner_list, Venn_title, Venn_file)
if(keep_time) toc()
}
if(play_audio) beep(sound = 6)
if(keep_time) tic("Comparing global properties")
# create a label and extract matrix for the analysis
global_all_df_2 <- global_all_df %>%
tidyr::separate(dataset, into = c("study", "type", "object"), remove = F) %>%
select(-type, -object) %>%
mutate(method_brief = case_when(
method == "spieceasi" ~ "spi",
method == "spring" ~ "spr",
method == "ccrepe" ~ "ccr",
method == "sparcc" ~ "spa"
)) %>%
tidyr::unite(label, study, method_brief, sep = "_", remove = F)
# keep only relevant columns and make a matrix
global_all_df_mat <- global_all_df_2 %>%
dplyr::select(label, nComp1:nnegedge, samples, Chao1, Pielou_J, ave_BC) %>%
column_to_rownames("label") %>% as.matrix()
# optionally obtain a scatterplot matrix
if(verbose_output) ggpairs(as.data.frame(global_all_df_mat), progress = F)
# look at the number of components (using correlation matrix)
var_to_use <- !(colnames(global_all_df_mat) %in% c("ncomp", "vertConnect1","edgeConnect1","ntaxa"))
psych::fa.parallel(global_all_df_mat[,c(1:5,8:14,17:18)], fa = "pc", n.iter = 100)
PCA1 <- psych::principal(global_all_df_mat[,c(1:5,8:14,17:18)], nfactors = 2, rotate = "varimax")
PCA1
biplot(PCA1, xlim.s = c(-1,4), ylim.s = c(-2,5), main = "PCA biplot, all variables")
fullnetscores <- cbind(global_all_df_2,PCA1$scores)
# the score plot
ggplot(fullnetscores, mapping = aes(x = RC1, y = RC2, shape = method, colour = study)) +
geom_point() +
labs(title = "all variables") +
scale_shape_manual(values = c("spieceasi" = 16, "spring" = 17, "ccrepe" = 15, "sparcc" = 18)) +
scale_color_brewer(type = "qual", palette = "Paired") +
theme(plot.title = element_text(hjust = 0.5))
var_to_use <- colnames(global_all_df_mat) %in% c("ncomp1", "modularity1","density1","clustCoef1",
"avPath1", "pep1", "Pielou_J", "ave_BC", "nnodes")
cat("variables to use: ", var_to_use, "\n")
psych::fa.parallel(global_all_df_mat[,var_to_use], fa = "pc", n.iter = 100)
PCA2 <- principal(global_all_df_mat[,var_to_use], nfactors = 2, rotate = "varimax")
PCA2
biplot(PCA2)
fullnetscores_2 <- cbind(global_all_df_2,PCA2$scores)
var_acc_RC1 <- round(PCA2$Vaccounted[4,1],3)
var_acc_RC2 <- round(PCA2$Vaccounted[4,2],3)
# the score plot
ggplot(fullnetscores_2, mapping = aes(x = RC1, y = RC2, shape = method, colour = study)) +
geom_point() +
labs(title = "selected variables") +
scale_shape_manual(values = c("spieceasi" = 16, "spring" = 17, "ccrepe" = 15, "sparcc" = 18)) +
scale_color_brewer(type = "qual", palette = "Paired") +
labs(x = paste("RC1 (", var_acc_RC1, ")", sep =""),
x = paste("RC2 (", var_acc_RC2, ")", sep ="")) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggsave(filename = paste(file.path(output_folder,out_filename_pref), "_PCA.tiff",sep=""), device = "tiff", width = 6,
height = 5, units = "in", dpi=600)
if(keep_time) toc()
if(keep_time) tic("Comparing global properties on LCC")
# create a label and extract matrix for the analysis
global_all_df_3 <- global_lcc_df %>%
tidyr::separate(dataset, into = c("study", "type", "object"), remove = F) %>%
select(-type, -object) %>%
mutate(method_brief = case_when(
method == "spieceasi" ~ "spi",
method == "spring" ~ "spr",
method == "ccrepe" ~ "ccr",
method == "sparcc" ~ "spa"
)) %>%
tidyr::unite(label, study, obj_type, method_brief, sep = "_", remove = F)
# keep only relevant columns and make matrix
global_all_df_mat_2 <- global_all_df_3 %>%
dplyr::select(label, lccSize1:nnegedge, samples, Chao1, Pielou_J, ave_BC) %>%
column_to_rownames("label") %>% as.matrix()
# need to remove an Inf value, I am removing the row
# obtain a scatterplot matrix
if(verbose_output) ggpairs(as.data.frame(global_all_df_mat_2[-3,]), progress = F)
# look at the number of components (using correlation matrix): must exclude
# ave path length and clustering coefficient which contain Inf and NaN
psych::fa.parallel(global_all_df_mat_2[-3,c(1:3,6,9:14,17:18)], fa = "pc", n.iter = 100)
PCA1_lcc <- psych::principal(global_all_df_mat_2[-3,c(1:3,6,9:14,17:18)], nfactors = 2, rotate = "varimax")
PCA1_lcc
biplot(PCA1_lcc, main = "PCA biplot, all variables")
fullnetscores_lcc <- cbind(global_all_df_3[-3,],PCA1_lcc$scores)
# the score plot
ggplot(fullnetscores_lcc, mapping = aes(x = RC1, y = RC2, shape = method, colour = study)) +
geom_point() +
labs(title = "all variables") +
scale_shape_manual(values = c("spieceasi" = 16, "spring" = 17, "ccrepe" = 15, "sparcc" = 18)) +
scale_color_brewer(type = "qual", palette = "Paired") +
theme(plot.title = element_text(hjust = 0.5))
var_to_use_lcc <- colnames(global_all_df_mat) %in% c("lccSize1", "modularity1","density1", "pep1", "Pielou_J", "ave_BC", "nnodes")
cat("variables to use: ", var_to_use_lcc, "\n")
psych::fa.parallel(global_all_df_mat_2[-3,var_to_use_lcc], fa = "pc", n.iter = 100)
PCA2_lcc <- principal(global_all_df_mat_2[-3,var_to_use_lcc], nfactors = 2, rotate = "varimax")
PCA2_lcc
biplot(PCA2_lcc)
fullnetscores_2_lcc <- cbind(global_all_df_2[-3,],PCA2_lcc$scores)
# the score plot
var_acc_RC1_lcc <- round(PCA2$Vaccounted[4,1],3)
var_acc_RC2_lcc <- round(PCA2$Vaccounted[4,2],3)
# the score plot
ggplot(fullnetscores_2_lcc, mapping = aes(x = RC1, y = RC2, shape = method, colour = study)) +
geom_point() +
labs(title = "selected variables") +
scale_shape_manual(values = c("spieceasi" = 16, "spring" = 17, "ccrepe" = 15, "sparcc" = 18)) +
scale_color_brewer(type = "qual", palette = "Paired") +
labs(x = paste("RC1 (", var_acc_RC1_lcc, ")", sep =""),
x = paste("RC2 (", var_acc_RC2_lcc, ")", sep ="")) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggsave(filename = paste(file.path(output_folder,out_filename_pref), "_PCA_lcc.tiff",sep=""), device = "tiff", width = 6,
height = 5, units = "in", dpi=600)
if(keep_time) toc()
if(keep_time) tic("Plotting the networks with ggraph")
# create a list of network plots
netplot_list <- vector("list", length = length(tidygraph_list_wstats))
for(i in seq_along(tidygraph_list_wstats)){
netplot_list_2 <- vector("list", length = length(tidygraph_list_wstats[[i]]))
dtst <- names(tidygraph_list_wstats)[i]
for(j in seq_along(tidygraph_list_wstats[[i]])){
if(!is.tbl_graph(tidygraph_list_wstats[[i]][[j]])){
netplot_list_2[[j]] <- "no plot to return"
next
} else {
tg <- tidygraph_list_wstats[[i]][[j]]
mthd <- names(tidygraph_list_wstats[[i]])[j]
# the default for the argument c0l0r is phylum, otherwise
# use c0l0r = clust_memb
# argument lp = "bottom" is the default; "right" is an alternative
netplot_list_2[[j]] <- plot_ggraph(tidy_graph = tg,
method = mthd,
name = dtst,
lp = "right")
names(netplot_list_2)[j] <- mthd
print(netplot_list_2[[j]])
}
}
netplot_list[[i]] <- netplot_list_2
names(netplot_list)[i] <- dtst
}
rm(tg, dtst, mthd, netplot_list_2)
if(play_audio) beep(sound = 6)
if(keep_time) toc()
if(keep_time) tic("Node analysis")
mymethods <- c("spieceasi","sparcc")
n_to_label <- 20 # max number of nodes to label in the node plots
node_analysis_list <- vector("list", length = length(mymethods))
for(i in seq_along(mymethods)){
# create the dfs, one for spiec-easi and one for sparCC and only select FMBN
# only select nodes with degree>0
FMBN_node_df <- node_stats_df %>%
dplyr::filter(method == mymethods[i]) %>%
dplyr::filter(degree>0) %>%
mutate(Study = as.factor(Study),
rel_pos_degree = pos_degree / sum(pos_degree)) %>%
dplyr::rename(tlabel = label)
# use a loop to do the node degree graphs, print them and put them in a list
node_degree_plot_list <- vector("list", length=nlevels(FMBN_node_df$study))
for(j in seq_along(levels(FMBN_node_df$Study))){
gtitle = paste(levels(FMBN_node_df$Study)[j], mymethods[i], sep = ", ")
temp_df <- FMBN_node_df %>%
dplyr::filter(Study ==levels(FMBN_node_df$Study)[j]) %>%
mutate(dgr = pos_degree + neg_degree) %>%
arrange(-dgr) %>%
rowid_to_column() %>%
mutate(to_label = if_else((rowid<=20 | is_hub), tlabel, NA_character_))
ave_degree = mean(temp_df$dgr, na.rm = T)
ave_pos_degree = mean(temp_df$pos_degree, na.rm = T)
# creating the plot, only the names of the top 20 nodes (in terms of degree)
# are plotted, hubs are always plotted
ggp <- ggplot(
temp_df,
mapping = aes(
x = pos_degree,
y = dgr,
label = str_trunc(genus, 12, side = "center")
)
) +
geom_smooth(method = "lm", linetype = 3, se = F, color = I("black"), show.legend = F) +
geom_point(mapping = aes(color = phylum,
size = relAbundance,
alpha = between)) +
geom_text_repel(show.legend = F, max.overlaps = 20, alpha = I(0.5)) +
geom_abline(slope = 1, intercept = 0, linetype = 1) +
geom_hline(yintercept = ave_degree, linetype = 3, show.legend = F) +
geom_vline(xintercept = ave_pos_degree, linetype = 3, show.legend = F) +
scale_alpha_continuous(range = c(0.4, 1)) +
scale_size_continuous(range = c(1,6)) +
labs(
x = "positive degree",
y = "degree",
size = "relative abundance",
alpha = "betweenness",
title = gtitle
) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
print(ggp)
node_degree_plot_list[[j]] <- ggp
names(node_degree_plot_list[[j]]) <- gtitle
}
file_name <- paste(file.path(output_folder,out_filename_pref), "_", mymethods[i], "_nodeplots.Rdata",sep="")
save(node_degree_plot_list, file = file_name)
# calculate frequency for hubs (meaningful only if you have many taxa and the percentile for hub detection is low, say 0.75-0.90)
n_datasets <- dplyr::n_distinct(FMBN_node_df$dataset)
FMBN_node_df_hubs <- FMBN_node_df %>%
dplyr::filter(is_hub == T) %>%
group_by(tlabel, phylum, class) %>%
summarise(hub_freq = n()/n_datasets) %>%
arrange(-hub_freq)
cat("method", mymethods[i], "hub frequency", "\n")
head(FMBN_node_df_hubs, 20)
# save elements in the list
node_analysis_list[[i]] <- list(
node_df = FMBN_node_df,
plot_list = node_degree_plot_list,
node_df_hubs = FMBN_node_df_hubs
)
names(node_analysis_list)[i]<- mymethods[i]
}
if(play_audio) beep(sound = 6)
if(keep_time) toc()
rm(FMBN_node_df, node_degree_plot_list, temp_df, FMBN_node_df_hubs)
if(keep_time) tic("Edge analysis")
# this calculates the empirical quantile of edge betweenness
# by dataset and method: I suppose one can then select those >0.95
# to get a sort of hubness for edges, but it makes sense only for
# large number of edges
edge_list_df <- edge_list_df %>% group_by(dataset, method) %>%
mutate(ebq = ecdf(edge_betw)(edge_betw)) %>% ungroup()
# calculate the frequency of edges, by study and type and
# median value and IQR for IQR
# this only checks for conserved edges across methods
edge_freq_bystudy <- edge_list_df %>%
group_by(dataset, asso_type, edge_name) %>%
summarise(n = n(),
med_ebq = median(ebq),
iqr_ebq = IQR(ebq)) %>%
arrange(-n, -med_ebq, ) %>%
ungroup()
# I am now generating a plot may be with the top 50 edges, only for FMBN studies
edge_freq_bystudy_FMBN <- edge_freq_bystudy %>%
dplyr::filter(str_detect(dataset, "FMBN")) %>%
arrange(-n, -med_ebq)
# let's try a plot (gives an emphasis to most stable edges)
slice_to_plot <- slice(edge_freq_bystudy_FMBN, 1:50) %>%
mutate(edge_name = forcats::fct_reorder(edge_name, med_ebq))
ggplot(slice_to_plot,
mapping = aes(x = edge_name, y = med_ebq, size = n, color = asso_type)) +
geom_point() +
coord_flip() +
labs(x = "edge", y = "edge betweenness quantile",
size = "edge freq.") +
scale_colour_manual(values = c("green","red"))
# same, by method and assotype, only for FMBN
# only meaningful for high number of studies
edge_freq_bymethod <- edge_list_df %>%
dplyr::filter(str_detect(dataset, "FMBN")) %>%
group_by(method, asso_type) %>%
count(edge_name) %>%
arrange(method, asso_type, -n)
# The following section evaluates taxonomic assortativity (i.e. evaluates if
# copresence associations are more frequent among members of the same
# family, order or class). The odds ratio of copresence relationships within
# the same family is calculated using epiR::epi.2by2()
# first, add taxonomy to the
unique_tax <- node_stats_df %>%
dplyr::select(label, domain:species) %>%
distinct()
edge_list_df_wtaxa <- edge_list_df
edge_list_df_wtaxa <- left_join(edge_list_df_wtaxa,
dplyr::select(unique_tax, label, class, order, family),
by = c("from_name" = "label")) %>%
dplyr::rename(from_class = class, from_order = order, from_family = family)
edge_list_df_wtaxa <- left_join(edge_list_df_wtaxa,
dplyr::select(unique_tax, label, class, order, family),
by = c("to_name" = "label")) %>%
dplyr::rename(to_class = class, to_order = order, to_family = family)
# check if same family or same class
edge_list_df_wtaxa <- edge_list_df_wtaxa %>%
mutate(same_class = if_else(from_class == to_class, T, F),
same_order = if_else(from_order == to_order, T, F),
same_family = if_else(from_family == to_family, T, F)
)
# use a loop to calculate odds ratios and probabilities
# get the number of studies
edge_list_df_wtaxa <- edge_list_df_wtaxa %>%
separate(dataset, into = c("study", "col2", "col3"), remove = F) %>%
select(-col2, -col3) %>%
mutate(study = as.factor(study),
sf = factor(same_family, levels = c("TRUE", "FALSE")),
so = factor(same_order, levels = c("TRUE", "FALSE")),
sc = factor(same_class, levels = c("TRUE", "FALSE"))
)
assort_results_list <- vector(mode = "list", length = nlevels(edge_list_df_wtaxa$study))
taxo_level_selection <- "family"
for(i in seq_along(levels(edge_list_df_wtaxa$study))){
input_df_study <- edge_list_df_wtaxa %>% dplyr::filter(study == levels(study)[i]) %>%
mutate(method = as.factor(method))
inner_result_list <- vector(mode = "list", length = nlevels(input_df_study$method))
for(j in seq_along(levels(input_df_study$method))){
input_df_method <- input_df_study %>%
mutate(method = as.factor(method)) %>%
dplyr::filter(method == levels(method)[j])
inner_result_list[[j]]<-try(odds_ratio(input_df_method, taxo_level = taxo_level_selection))
names(inner_result_list)[j]<- levels(input_df_method$method)[j]
}
assort_results_list[[i]] <- inner_result_list
names(assort_results_list)[i] <- levels(edge_list_df_wtaxa$study)[i]
}
# clean-up the list and put together the data frames
df_list <- vector(mode = "list", length = length(assort_results_list))
for(i in seq_along(assort_results_list)){
df_list[[i]] <- df_return(assort_results_list[[i]])
names(df_list)[i]<-names(assort_results_list)[i]
}
assort_results_df <- bind_rows(df_list, .id = "study")
# create dummy ORest values by replacing Inf
assort_results_df <- assort_results_df %>%
mutate(OR_est_wdummy = if_else(OR_est==Inf, 99, OR_est)) %>%
mutate(lOR_est_wdummy = log(OR_est_wdummy),
significant = if_else(OR_p.value <=0.05, T, F))
# plot, studies are pooled
ggplot(assort_results_df, mapping = aes(x = assort_test, y = lOR_est_wdummy, colour = significant)) +
facet_wrap(~method) +
geom_jitter(width = 0.2) +
labs(y = "odds ratio")
rm(assort_results_list, input_df_study, inner_result_list, input_df_method, i, j, df_list)
if(play_audio) beep(sound = 6)
if(keep_time) toc()
all_packages <- c("base", .cran_packages, .bioc_packages, .github_packages)
map(all_packages, citation)
# for reproducibility you should also run
# sessionInfo()
View(study_metadata)
